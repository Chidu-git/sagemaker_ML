{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5cd3d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boto3 => Python library for calling up AWS services\n",
    "import boto3,os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "role = get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a655665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#provide the name and location of the files to be stored in the S3 bucket\n",
    "bucket_name = 'sagemaker-chidu'\n",
    "train_file_name = 'Train_final.csv'\n",
    "val_file_name = 'Validation_final.csv'\n",
    "test_file_name = 'Test_final.csv'\n",
    "\n",
    "model_output_location = r's3://{0}/LoanPrediction/model'.format(bucket_name)\n",
    "train_file_location = r's3://{0}/{1}'.format(bucket_name, train_file_name)\n",
    "val_file_location = r's3://{0}/{1}'.format(bucket_name, val_file_name)\n",
    "test_file_location = r's3://{0}/{1}'.format(bucket_name, test_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb55f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the train file into train and validation.\n",
    "\n",
    "df=pd.read_csv(\"Train_file.csv\")\n",
    "train,val = np.split(df,[ int(len(df)*0.8)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be3b160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"Train_data_file.csv\",index=False)\n",
    "val.to_csv(\"Validation_file.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a1a419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#brinigng the traget column as the first column\n",
    "def col_to_first(file_name):\n",
    "    df=pd.read_csv(file_name)\n",
    "    cols=list(df.columns)\n",
    "    cols=[cols[-1]]+cols[:-1]\n",
    "    df=df[cols]\n",
    "    df[\"Loan_Status\"]=df[\"Loan_Status\"].apply(lambda x:0 if x==\"Y\" else 1)\n",
    "    df.to_csv(file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3bbf3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_first(\"Train_data_file.csv\")\n",
    "col_to_first(\"Validation_file.csv\")\n",
    "# col_to_first(\"Test_file.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf7f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a method for writing into s3 bucket\n",
    "def write_to_s3(filename, bucket, key):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c170591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_s3('Train_data_file.csv', bucket_name, train_file_name)\n",
    "write_to_s3('Validation_file.csv', bucket_name, val_file_name)\n",
    "write_to_s3('Test_file.csv', bucket_name, test_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79df7a2",
   "metadata": {},
   "source": [
    "other method of transfering data from sagemaker local to s3\n",
    "\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(('Train_file.csv')).upload_file('Train_file.csv')\n",
    "\n",
    "if respective folder is reqd then\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join('Train',Train_file.csv')).upload_file('Train_file.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4227a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2502765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":'binary:logistic',\n",
    "        \"num_round\":\"50\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca25814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "region=\"us-east-1\"\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, \"1.2-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd65a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'sagemaker-chidu'\n",
    "model_output_location = r's3://{0}/LoanPrediction/model'.format(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f57067a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.2xlarge', \n",
    "                                          volume_size=5, # 5 GB \n",
    "                                          output_path=model_output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68978cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data type and paths to the training and validation datasets\n",
    "content_type = \"csv\"\n",
    "# training_file = sagemaker.session.s3_input(s3_data=train_file_location, content_type =content_type)\n",
    "train_input = TrainingInput(\"s3://{0}/{1}\".format(bucket_name, train_file_name), content_type=content_type)\n",
    "validation_input = TrainingInput(\"s3://{0}/{1}\".format(bucket_name, val_file_name), content_type=content_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e150560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-22 09:03:27 Starting - Starting the training job...\n",
      "2021-10-22 09:03:52 Starting - Launching requested ML instancesProfilerReport-1634893407: InProgress\n",
      "......\n",
      "2021-10-22 09:04:52 Starting - Preparing the instances for training.........\n",
      "2021-10-22 09:06:13 Downloading - Downloading input data\n",
      "2021-10-22 09:06:13 Training - Downloading the training image...\n",
      "2021-10-22 09:06:54 Uploading - Uploading generated training model\u001b[34m[2021-10-22 09:06:50.480 ip-10-0-156-142.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-10-22:09:06:50:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2021-10-22:09:06:50:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2021-10-22:09:06:50:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-10-22:09:06:50:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2021-10-22:09:06:50:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-10-22:09:06:50:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-10-22:09:06:50:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-10-22:09:06:50:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-10-22:09:06:50:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2021-10-22:09:06:50:INFO] Train matrix has 492 rows and 11 columns\u001b[0m\n",
      "\u001b[34m[2021-10-22:09:06:50:INFO] Validation matrix has 124 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.19309#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.19106#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.19106#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.19106#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.19106#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.19106#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.19106#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.19106#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.19106#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.19106#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.19106#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.19106#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.18902#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.18699#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.18699#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.18699#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.18699#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.19106#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.19106#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.18496#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.18699#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.18902#011validation-error:0.18548\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.18902#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.18496#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.18496#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.18496#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.18496#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.18496#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.18496#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.18496#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.18496#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.18496#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.18293#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.17886#011validation-error:0.17742\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.17886#011validation-error:0.17742\u001b[0m\n",
      "\n",
      "2021-10-22 09:07:33 Completed - Training job completed\n",
      "ProfilerReport-1634893407: NoIssuesFound\n",
      "Training seconds: 62\n",
      "Billable seconds: 62\n"
     ]
    }
   ],
   "source": [
    "# execute the XGBoost training job\n",
    "estimator.fit({'train': train_input, 'validation': validation_input})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
